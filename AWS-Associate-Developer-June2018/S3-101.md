
# S3-101

    "Simple Storage Service"
    Object Storage only
    Data is spread over multiple facilities and devices.  Data is highly available.
    0 bytes to 5 TB
    Unlimited storage
    Bucket names must be unique globally.  The S3 namespace is universal.
    E.g. https://s3-eu-west-1.amazonaws.com/acoudguru
    A successful upload into S3 results in a HTTP 200.

## Data Consistency Model
    "Read after Write" consistency for PUTS of new objects.  You can read your file immediately after uploading it!
    "Eventual Consistency" for overwrites of PUTS and DELETES.  

## General
    S3 is a key-value store
    Key is the name of the object
    Value is the data.
    Version ID is used for versioning.
    Metadata
    Subresources include "Policies", "Access Control Lists", "Cross Origin Resource Sharing" and "Transfer Acceleration".
    
## SLAs
    S3 is designed for 99.99% availability.
    Amazon guarantee 99.9% availability.
    Amazon guarantee 99.(11 9's)% durability.

## Features
### Tiered Storage
### Lifecycle Management
### Versioning
 
	Versioning can be enabled at bucket level. 
	If enabled, S3 keeps every previous version of a file after an PUT/DELETE operation applied to it. 
	PUTtting the same file creates a new version of the latest and set it as the latest version.
	DELETE operation simply puts a marker (delete marker) as the latest version of the target file. 
	Therefore, it's similar to PUTting a delete marker as the latest version.
	
	Standard, GET operation simply returns the latest version to the client.
	Because a DELETE operation means inserting a marker as the latest version, client see the file as deleted.
	
	In order to DELETE a specific version of a file, that version should be specified explicitly in the request.
	Otherwise, it refers to the latest version.
	
	If versioning is not enabled for the bucket, then the simply is physically overwritten with the PUTted version.
	Same as DELETE actually deletes the file.
	
	One common point to remember with versioning, is previous versions of the files also use storage capacity, so
	will be counted on your storage limit as well. As an exception DELETE MARKER only requires space with respect to
	the length of the key name you used for the actual file.
	
### Encryption	
### ACLs and Policies
    
## Storage Tiers

### S3
    99.99% availability
    99.(11 9's)% durability
    Data storage across multiple devices and facilities.
    Designed for loss of 2 facilities.

### S3-IA
    Designed for less frequently accessed data.
    Supports rapid access
    Lower fee but you are charged a retrieval fee.
    
### S3 One Zone IA
    Same as S3-IA but stored on one AZ.
    99.5% availability
    99.(11 9's)% durability
    Cost is 20% less that S3-IA.
    
### Reduced Redundancy Storage
    99.99% availability
    99.99% durability
    For data that can be easily recreated (e.g. thumbnails).
    
### Glacier
    For data that is archived.
    Recovery time is 3-5 hours.
    Very cheap.
    
### S3 Intelligent Tiering
    For data with unknown or unpredictable access pattern.
    2 tiers - Frequent and Infrequent Access
    AWS moves your data to the most cost-effective tier based on how frequently your data is accessed.
    99.9% availability
    99.(11 9's)% durability
    Small fee charged per month for each 1000 objects.
    
## S3 Charges
    Charged per GB
    Charged per requests
    Charged per Tags, Analytics and Inventory(?)
    Charged per download from S3. There is no charge for IN traffic to S3.
    Charged for "Transfer Acceleration".  TA used CloudFront to speed up upload times.
  
## S3 Security
    Buckets are private by default
    "Bucket Policies" applied at bucket level (written in JSON)
    "Access Control Lists" applied at object level.  ACLs describe which accounts/groups have read/write access to objects.
    Buckets can be configured to log all access to a bucket.  Logs can be written to another bucket.
    
## S3 Lab
    When creating a bucket, you can click a checkbox taht will retain all versions of each object in this bucket. 
    When creating a bucket, you can optionally select to encrypt your bucket.
    When uploading objects to your bucket, you may select ACLs and the storage class for this object.
    
## S3 Encryption
    Encryption in Transit
      SSL or TLS
      
    Encryption at Rest
      Server side encryption
        S3 Managed Keys (SSE-S3)
          Each object is encrypted with its own key.
          Each key is then encrypted with a master key which is regularly rotated.
        
        AWS Key Management Service or SSE-KMS
          Each object is encrypted with its own key.
          You are then given access to an "envelope" key which is used to encrypt each of the above keys.
          You also get an audit trail to log the use of your "envelope" key.
          You can supply your own key to use as the envelope key, or you may use the default key which Amazon provide.

        Server side encryption with Customer provided keys (SSE-C)
          AWS perform encryption/decryption but you provide the keys.
      
      Client side encryption
        You encrypt the files yourself before uploading them to S3.
        
### Enforcing encryption on S3 buckets
    Files are uploaded to S3 via HTTP PUT requests.
    "Expect: 100-continue" is a header in the PUT request.  This allows S3 to reject the request before the body has been submitted.
    To request a file to be encrypted on upload, the request must include "x-amz-server-side-encryption: AES256" or "x-amz-server-side-encryption: ams:kms"
    Your bucket policy may require that each header includes "x-amz-server-side-encryption".
    
## Cross Origin Resource Sharing (CORS)
    Allows bucket1 to access resources in bucket2.
    CORS must be enabled on bucket2.
    CORS is enabled by a <CORSConfiguration> block of XML which is applied to bucket2.
    The xml explicitly allows bucket1 to GET bucket2's resources.
    
## CloudFront
    A Content Delivery Network (CDN) is a network of geographically distributed servers that deliver content to a user based on the location of the user.
    
    A CDN is a service that speeds up upload and download times depending on your users' geographic location.  
    
    S3 Transfer Acceleration makes use of CloudFront to achieve faster uploads into S3.
    
    CloudFront employs a collection of geographically distributed servers (Edge Locations) to act as a Cache for Users' objects in S3.
    
    The first time an object is request to S3, Amazon will store that object in a suitable Edge Location.  The next time that object is requested from a user in the same geographic location, it is downloaded from the Edge Location.
    
    Objects remain in an Edge Location for a period known as the Time To live (TTL).
    An Edge Location's cache may be manually cleared (called invalidation). This will incur an extra charge from Amazon.
    
    An "Origin" is the origin of all files that the CDN will distribute.  E.g. S3 Bucket, EC2 Instance, ELB or Route 53.
    A "Distrbution" is the name given to the CDN which contains a collection of Edge Locations.
    
    There are two CloudFront Distribution Types:
       * Web Distribution - Used for web sites.
       * RTMP - Used for Media Streaming.
       
# S3 Performance
    In July 2018, S3 performance was upgraded.
        * 3,500 PUT requests per second
        * 5,500 GET requests per second
        
    No need to randomise your objects keyname in order to prevent hot-spotting of an S3 server.  
    
# From the FAQ

    https://aws.amazon.com/s3/faqs/

    Min file size is 0 bytes
    Max file size is 5 TB
    Max upload size is 5 GB
    If you want to upload a file greater than 5GB then you must use the [multi-part upload API](https://docs.aws.amazon.com/AmazonS3/latest/dev/UploadingObjects.html).
    You can use a multipart upload for objects from 5 MB to 5 TB in size.
    
    The S3 Standard storage class is designed for 99.99% availability
    The S3 Standard-IA storage class is designed for 99.9% availability
    The S3 One Zone-IA storage class is designed for 99.5% availability. 
    
    You specify an AWS Region when you create your Amazon S3 bucket.
    Objects stored in the S3 One Zone-IA storage class are stored redundantly within a single Availability Zone in the AWS Region you select.
    The Amazon S3 One Zone-IA storage class replicates data within a single AZ.
    
    
    

    
